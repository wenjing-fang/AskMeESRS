{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import json\n",
    "import time\n",
    "from bs4 import Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup headless browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Load the page\n",
    "url = \"https://xbrl.efrag.org/e-esrs/esrs-set1-2023.html\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Streamed JSON written to text/esrs_streamed.json,2312 items\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with open(\"scraped_text/esrs_streamed.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"[\\n\")\n",
    "    first = True\n",
    "    current_id = None\n",
    "    main_container = soup.find(\"div\", class_=\"eli-container\", id=\"anx_I\")\n",
    "\n",
    "    for item in main_container.children: # one item is either a section-title, a subsetion-title, or a paragraph\n",
    "        item_extracted = None  \n",
    "        if item.name == \"p\" or (item.name == \"a\" and item.has_attr(\"id\")): # p and a (all except appendix)\n",
    "            # section and subsection\n",
    "            if item.name == \"p\": \n",
    "                direct_text = item.find(string=True, recursive=False) # direct text under class\n",
    "                direct_text = direct_text.strip() if direct_text else \"\"\n",
    "\n",
    "                useful_child = item.find(\"span\")\n",
    "                child_text = useful_child.get_text(strip=True) if useful_child else \"\"\n",
    "\n",
    "                if direct_text.endswith('.'): # section\n",
    "                    item_extracted = {\n",
    "                        \"class_type_id\": f\"p_{item.get('id', '')}\",\n",
    "                        \"section_num\": direct_text,\n",
    "                        \"section_title\": child_text\n",
    "                    }\n",
    "                else: # subsection\n",
    "                    item_extracted = {\n",
    "                        \"class_type_id\": f\"p_{item.get('id', '')}\",\n",
    "                        \"subsection_num\": direct_text,\n",
    "                        \"subsection_title\": child_text\n",
    "                    }\n",
    "\n",
    "            # a paragraph, <singel-item (smallest unit)>\n",
    "            elif item.name == \"a\" and item.has_attr(\"id\"): \n",
    "                full_text = item.get_text(separator=\"\\n\", strip=True)\n",
    "                texts = full_text.split('\\n')\n",
    "                item_num = texts[0] if texts else ''\n",
    "                item_content = \" \".join(texts[1:]) if len(texts) > 1 else \"\"\n",
    "\n",
    "                item_extracted = {\n",
    "                    \"class_type_id\": f'a_{item[\"id\"]}',\n",
    "                    \"item_num\": item_num,\n",
    "                    \"item_content\": item_content\n",
    "                }\n",
    "\n",
    "            # ✅ Write it out either a p or a\n",
    "            if item_extracted:\n",
    "                if not first:\n",
    "                    f.write(\",\\n\")\n",
    "                else:\n",
    "                    first = False\n",
    "                f.write(json.dumps(item_extracted, ensure_ascii=False))\n",
    "                count += 1\n",
    "\n",
    "        # Appendix\n",
    "        elif item.name == \"div\" : # the appendixs, one item => one appendix. e.g.: Appendix A\n",
    "            tag_child = next((c for c in item.children if isinstance(c, Tag)), None)\n",
    "            item_extracted = None\n",
    "\n",
    "            if tag_child:\n",
    "                titles = [                  # section title \"Appendix A\", 'Application Requirements'\n",
    "                    p.get_text(strip=True)\n",
    "                    for p in tag_child.find_all(\"p\", class_=\"oj-doc-ti\")\n",
    "                    if p.get(\"class\") == [\"oj-doc-ti\"]\n",
    "                ]\n",
    "                item_extracted = {\n",
    "                    \"class_type_id\": f\"ar_section_no_id\",\n",
    "                    \"item_num\": titles[0],      # First content paragraph\n",
    "                    \"item_content\": titles[1],  # Second content paragraph\n",
    "                }\n",
    "                if item_extracted:\n",
    "                    # ✅ Write it out immediately\n",
    "                    if not first:\n",
    "                        f.write(\",\\n\")\n",
    "                    else:\n",
    "                        first = False\n",
    "                    f.write(json.dumps(item_extracted, ensure_ascii=False))\n",
    "                    count += 1\n",
    "\n",
    "                for sub_item in tag_child.children: # Below contain everything in one (Appendix A), is written two-level below 【☑️ check】\n",
    "                    item_extracted = None\n",
    "                    if sub_item.name == \"p\": # Section title, subsection-title, pre_para_note 【☑️ check】\n",
    "                        # print(sub_item.get('class'))\n",
    "                        if sub_item.get('class') == ['oj-doc-ti']:  # Section title\n",
    "                            continue\n",
    "                        elif sub_item.find(\"span\", class_=\"oj-italic\"): # pre_para_note, written in italic e.g.:'Stakeholders and their relevance to the materiality assessment process'\n",
    "                            item_extracted = {\n",
    "                                \"class_type_id\": f\"ar_pre_para_note_no_id\",\n",
    "                                \"item_num\": sub_item.get_text(strip=True), # get direct text\n",
    "                                \"item_content\": sub_item.get_text(strip=True), # get direct text\n",
    "                            }\n",
    "                        else: # subsection title, written in bold e.g.:'Entity specific disclosures'\n",
    "                            item_extracted = {\n",
    "                                \"class_type_id\": f\"ar_subsection_no_id\",\n",
    "                                \"item_num\": sub_item.get_text(strip=True), # get direct text\n",
    "                                \"item_content\": sub_item.get_text(strip=True), # get direct text\n",
    "                            }\n",
    "                            \n",
    "                    \n",
    "                    elif sub_item.name == \"a\" and sub_item.has_attr(\"id\"): # a paragraph, <singel-item (smallest unit)>\n",
    "                        full_text = sub_item.get_text(separator=\"\\n\", strip=True)\n",
    "                        texts = full_text.split('\\n')\n",
    "                        subitem_num = texts[0] if texts else ''\n",
    "                        subitem_content = \" \".join(texts[1:]) if len(texts) > 1 else \"\"\n",
    "\n",
    "                        item_extracted = {\n",
    "                            \"class_type_id\": f'ar_{sub_item[\"id\"]}',\n",
    "                            \"item_num\": subitem_num, # AR 1\n",
    "                            \"item_content\": subitem_content # content\n",
    "                        }\n",
    "\n",
    "                    # ✅ Write a item in appendix_class.child\n",
    "                    if item_extracted:\n",
    "                        if not first:\n",
    "                            f.write(\",\\n\")\n",
    "                        else:\n",
    "                            first = False\n",
    "                        f.write(json.dumps(item_extracted, ensure_ascii=False))\n",
    "                        count += 1\n",
    "\n",
    "    f.write(\"\\n]\")\n",
    "    print(f\"✅ Streamed JSON written to text/esrs_streamed.json,{count} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
